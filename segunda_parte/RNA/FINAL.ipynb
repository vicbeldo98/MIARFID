{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FINAL.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"id":"PBiUNMwbVy_P","executionInfo":{"status":"ok","timestamp":1643717274047,"user_tz":-60,"elapsed":862441,"user":{"displayName":"Victoria Beltrán Domínguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06355768364191725091"}},"outputId":"ac16bf23-5679-42f5-e963-888b5970cbf3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-f9e79dbb-b5f9-4d92-96f1-3efb19308700\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f9e79dbb-b5f9-4d92-96f1-3efb19308700\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving archive.zip to archive.zip\n"]}]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n","    zip_ref.extractall('.')"],"metadata":{"id":"WGm5kqD6Yu7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","print(os.listdir('.'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzfCZEofa8-x","executionInfo":{"status":"ok","timestamp":1643718621444,"user_tz":-60,"elapsed":7,"user":{"displayName":"Victoria Beltrán Domínguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06355768364191725091"}},"outputId":"fdd8c53a-2498-48d9-d4a9-4c699137f490"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['.config', 'archive.zip', 'test', 'train', 'sample_data']\n"]}]},{"cell_type":"markdown","source":["## **Dataset information**\n","The dataset contain 35,685 examples of 48x48 pixel gray scale images of faces divided into train and test dataset. \n","Images are categorized based on the emotion shown in the facial expressions:\n","\n","*   hapiness\n","*   neutral\n","*   sadness\n","*   anger\n","*   surprise\n","*   disgust\n","*   fear"],"metadata":{"id":"SQR4tmf7g2W3"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"vW3ovy-eCckU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643718635396,"user_tz":-60,"elapsed":4518,"user":{"displayName":"Victoria Beltrán Domínguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06355768364191725091"}},"outputId":"f4ce430b-766d-4bf7-891a-98f4dc7985a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 28709 images belonging to 7 classes.\n","Found 28709 images belonging to 7 classes.\n","Found 7178 images belonging to 7 classes.\n"]}],"source":["from __future__ import print_function\n","import keras\n","import tensorflow as tf\n","from keras.datasets import cifar10\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten, Input, Add\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n","from keras.layers import BatchNormalization as BN\n","from keras.layers import GaussianNoise as GN\n","from tensorflow.keras.optimizers import Adam\n","from keras.utils import np_utils\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.callbacks import LearningRateScheduler as LRS\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","import numpy as np\n","\n","\n","batch_size = 256\n","num_classes = 7\n","epochs = 50\n","\n","train_dir = 'train'\n","test_dir = 'test'\n","\n","\n","class CustomGenerator():\n","    def __init__(self, generator, directory, batch_size, alpha=0.3):\n","        self.batch_index = 0\n","        self.batch_size = batch_size\n","\n","        self.generator_X = generator.flow_from_directory(directory,\n","                                                        target_size=(48, 48),\n","                                                        class_mode=\"categorical\",\n","                                                        color_mode='grayscale',\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True)\n","        \n","        self.generator_Y = generator.flow_from_directory(directory,\n","                                                        target_size=(48, 48),\n","                                                        class_mode=\"categorical\",\n","                                                        color_mode='grayscale',\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True)\n","        self.n = self.generator_X.samples\n","        self.alpha = alpha\n","\n","    def reset_index(self):\n","        self.generator_X._set_index_array()\n","        self.generator_Y._set_index_array()\n","\n","    def on_epoch_end(self):\n","        self.reset_index()\n","\n","    def reset(self):\n","        self.batch_index = 0\n","\n","    def __len__(self):\n","        return (self.n + self.batch_size - 1) // self.batch_size\n","\n","    def get_steps_per_epoch(self):\n","        return self.n // self.batch_size\n","\n","    def __next__(self):\n","        if self.batch_index == 0:\n","            self.reset_index()\n","\n","        current_index = (self.batch_index * self.batch_size) % self.n\n","        if self.n > current_index + self.batch_size:\n","            self.batch_index += 1\n","        else:\n","            self.batch_index = 0\n","        X1, y1 = self.generator_X.next()\n","        X2, y2 = self.generator_Y.next()\n","\n","        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])\n","        X_l = l.reshape(X1.shape[0], 1, 1, 1)\n","        y_l = l.reshape(X1.shape[0], 1)\n","\n","        X = X1 * X_l + X2 * (1 - X_l)\n","        y = y1 * y_l + y2 * (1 - y_l)\n","        return X, y\n","\n","    def __iter__(self):\n","        while True:\n","            yield next(self)\n","\n","\n","datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        rotation_range=30,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True\n",")\n","\n","train_dataset = CustomGenerator(datagen, train_dir, batch_size)\n","\n","test_dataset = datagen.flow_from_directory(test_dir,\n","                                           target_size=(48, 48),\n","                                           class_mode=\"categorical\",\n","                                           color_mode='grayscale',\n","                                           batch_size=batch_size,\n","                                           shuffle=True)"]},{"cell_type":"code","source":["# Definición de la red\n","def resnet_layer(inputs, filters, apply_stride=False):\n","    x = inputs\n","\n","    if apply_stride:\n","      x = Conv2D(filters, (3, 3), strides=2, padding='same')(x)\n","    else:\n","      x = Conv2D(filters, (3, 3), padding='same')(x)\n","\n","    x = BN()(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(filters, (3, 3), padding='same')(x)\n","    x = BN()(x)\n","\n","    if apply_stride:\n","      previous = Conv2D(filters, (1,1), strides=2, padding='same')(inputs)\n","    else:\n","      previous = Conv2D(filters, (1,1), padding='same')(inputs)\n","\n","    x = Add()([previous,x])\n","    x = Activation('relu')(x)\n","\n","    return x\n","\n","inputs = Input(shape=(48, 48, 1))\n","\n","x = resnet_layer(inputs, 128)\n","x = resnet_layer(x, 128)\n","\n","x = resnet_layer(x, 256, True)\n","x = resnet_layer(x, 256)\n","\n","\n","x = resnet_layer(x, 512, True)\n","x = resnet_layer(x, 512)\n","\n","\n","x = GlobalAveragePooling2D()(x)\n","\n","x = Dense(num_classes)(x)\n","x = Activation('softmax')(x)\n","\n","model = Model(inputs=inputs, outputs=x)\n","model.summary()\n","\n","\n","## OPTIM AND COMPILE\n","opt = Adam(learning_rate=0.001)\n","\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# DEFINE A LEARNING RATE SCHEDULER\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.000001)\n","\n","## TRAINING with DA and LRA\n","history = model.fit(train_dataset,\n","                    epochs = epochs,\n","                    steps_per_epoch= 28709/ batch_size,\n","                    callbacks=[reduce_lr],\n","                    validation_data=test_dataset,\n","                    verbose=1)\n","\n","## TEST\n","scores = model.evaluate(test_dataset, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUU4HrWhD-CR","outputId":"68f6bad7-5fb8-4bbe-c5f3-56e0469ba735","executionInfo":{"status":"ok","timestamp":1643729905546,"user_tz":-60,"elapsed":11266433,"user":{"displayName":"Victoria Beltrán Domínguez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06355768364191725091"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 48, 48, 128)  1280        ['input_2[0][0]']                \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 48, 48, 128)  512        ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 48, 48, 128)  0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 48, 48, 128)  147584      ['activation_13[0][0]']          \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 48, 48, 128)  256         ['input_2[0][0]']                \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 48, 48, 128)  512        ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 48, 48, 128)  0           ['conv2d_20[0][0]',              \n","                                                                  'batch_normalization_13[0][0]'] \n","                                                                                                  \n"," activation_14 (Activation)     (None, 48, 48, 128)  0           ['add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 48, 48, 128)  147584      ['activation_14[0][0]']          \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 48, 48, 128)  512        ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 48, 48, 128)  0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 48, 48, 128)  147584      ['activation_15[0][0]']          \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 48, 48, 128)  16512       ['activation_14[0][0]']          \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 48, 48, 128)  512        ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 48, 48, 128)  0           ['conv2d_23[0][0]',              \n","                                                                  'batch_normalization_15[0][0]'] \n","                                                                                                  \n"," activation_16 (Activation)     (None, 48, 48, 128)  0           ['add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 24, 24, 256)  295168      ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 24, 24, 256)  1024       ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 24, 24, 256)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 24, 24, 256)  590080      ['activation_17[0][0]']          \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 24, 24, 256)  33024       ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 24, 24, 256)  1024       ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 24, 24, 256)  0           ['conv2d_26[0][0]',              \n","                                                                  'batch_normalization_17[0][0]'] \n","                                                                                                  \n"," activation_18 (Activation)     (None, 24, 24, 256)  0           ['add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 24, 24, 256)  590080      ['activation_18[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 24, 24, 256)  1024       ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 24, 24, 256)  0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 24, 24, 256)  590080      ['activation_19[0][0]']          \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 24, 24, 256)  65792       ['activation_18[0][0]']          \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 24, 24, 256)  1024       ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 24, 24, 256)  0           ['conv2d_29[0][0]',              \n","                                                                  'batch_normalization_19[0][0]'] \n","                                                                                                  \n"," activation_20 (Activation)     (None, 24, 24, 256)  0           ['add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 12, 12, 512)  1180160     ['activation_20[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 12, 12, 512)  2048       ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 12, 12, 512)  0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 12, 12, 512)  2359808     ['activation_21[0][0]']          \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 12, 12, 512)  131584      ['activation_20[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 12, 12, 512)  2048       ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 12, 12, 512)  0           ['conv2d_32[0][0]',              \n","                                                                  'batch_normalization_21[0][0]'] \n","                                                                                                  \n"," activation_22 (Activation)     (None, 12, 12, 512)  0           ['add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 12, 12, 512)  2359808     ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 12, 12, 512)  2048       ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 12, 12, 512)  0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 12, 12, 512)  2359808     ['activation_23[0][0]']          \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 12, 12, 512)  262656      ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 12, 12, 512)  2048       ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 12, 12, 512)  0           ['conv2d_35[0][0]',              \n","                                                                  'batch_normalization_23[0][0]'] \n","                                                                                                  \n"," activation_24 (Activation)     (None, 12, 12, 512)  0           ['add_11[0][0]']                 \n","                                                                                                  \n"," global_average_pooling2d_1 (Gl  (None, 512)         0           ['activation_24[0][0]']          \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," dense_1 (Dense)                (None, 7)            3591        ['global_average_pooling2d_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," activation_25 (Activation)     (None, 7)            0           ['dense_1[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 11,296,775\n","Trainable params: 11,289,607\n","Non-trainable params: 7,168\n","__________________________________________________________________________________________________\n","Epoch 1/50\n","112/112 [==============================] - 228s 2s/step - loss: 1.8645 - accuracy: 0.2476 - val_loss: 1.8173 - val_accuracy: 0.2471 - lr: 0.0010\n","Epoch 2/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.7877 - accuracy: 0.2595 - val_loss: 1.8440 - val_accuracy: 0.2471 - lr: 0.0010\n","Epoch 3/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.7719 - accuracy: 0.2732 - val_loss: 1.8564 - val_accuracy: 0.2471 - lr: 0.0010\n","Epoch 4/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.7148 - accuracy: 0.3121 - val_loss: 1.8858 - val_accuracy: 0.1747 - lr: 0.0010\n","Epoch 5/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.6090 - accuracy: 0.3833 - val_loss: 1.7150 - val_accuracy: 0.3155 - lr: 0.0010\n","Epoch 6/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.5261 - accuracy: 0.4312 - val_loss: 1.8450 - val_accuracy: 0.3274 - lr: 0.0010\n","Epoch 7/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.4581 - accuracy: 0.4701 - val_loss: 1.4577 - val_accuracy: 0.4355 - lr: 0.0010\n","Epoch 8/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.4011 - accuracy: 0.4985 - val_loss: 1.5115 - val_accuracy: 0.4257 - lr: 0.0010\n","Epoch 9/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.3513 - accuracy: 0.5231 - val_loss: 1.4279 - val_accuracy: 0.4595 - lr: 0.0010\n","Epoch 10/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.3305 - accuracy: 0.5356 - val_loss: 1.3631 - val_accuracy: 0.4911 - lr: 0.0010\n","Epoch 11/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.3006 - accuracy: 0.5527 - val_loss: 1.2992 - val_accuracy: 0.5098 - lr: 0.0010\n","Epoch 12/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.2790 - accuracy: 0.5613 - val_loss: 1.2136 - val_accuracy: 0.5476 - lr: 0.0010\n","Epoch 13/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.2630 - accuracy: 0.5691 - val_loss: 1.3645 - val_accuracy: 0.4870 - lr: 0.0010\n","Epoch 14/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.2498 - accuracy: 0.5771 - val_loss: 1.1697 - val_accuracy: 0.5632 - lr: 0.0010\n","Epoch 15/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.2287 - accuracy: 0.5871 - val_loss: 1.1383 - val_accuracy: 0.5779 - lr: 0.0010\n","Epoch 16/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.2206 - accuracy: 0.5903 - val_loss: 1.1406 - val_accuracy: 0.5729 - lr: 0.0010\n","Epoch 17/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.2027 - accuracy: 0.5944 - val_loss: 1.2074 - val_accuracy: 0.5515 - lr: 0.0010\n","Epoch 18/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.1952 - accuracy: 0.6038 - val_loss: 1.0996 - val_accuracy: 0.5821 - lr: 0.0010\n","Epoch 19/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1813 - accuracy: 0.6078 - val_loss: 1.0999 - val_accuracy: 0.5910 - lr: 0.0010\n","Epoch 20/50\n","112/112 [==============================] - 227s 2s/step - loss: 1.1705 - accuracy: 0.6140 - val_loss: 1.1097 - val_accuracy: 0.5886 - lr: 0.0010\n","Epoch 21/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1645 - accuracy: 0.6181 - val_loss: 1.0870 - val_accuracy: 0.5988 - lr: 0.0010\n","Epoch 22/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1511 - accuracy: 0.6223 - val_loss: 1.0675 - val_accuracy: 0.6024 - lr: 0.0010\n","Epoch 23/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1444 - accuracy: 0.6295 - val_loss: 1.1258 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 24/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1407 - accuracy: 0.6289 - val_loss: 1.0815 - val_accuracy: 0.5972 - lr: 0.0010\n","Epoch 25/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1311 - accuracy: 0.6356 - val_loss: 1.2145 - val_accuracy: 0.5670 - lr: 0.0010\n","Epoch 26/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1328 - accuracy: 0.6320 - val_loss: 1.0654 - val_accuracy: 0.6032 - lr: 0.0010\n","Epoch 27/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1194 - accuracy: 0.6399 - val_loss: 1.0316 - val_accuracy: 0.6151 - lr: 0.0010\n","Epoch 28/50\n","112/112 [==============================] - 225s 2s/step - loss: 1.1028 - accuracy: 0.6451 - val_loss: 1.1142 - val_accuracy: 0.5921 - lr: 0.0010\n","Epoch 29/50\n","112/112 [==============================] - 226s 2s/step - loss: 1.1079 - accuracy: 0.6447 - val_loss: 1.0255 - val_accuracy: 0.6230 - lr: 0.0010\n","Epoch 30/50\n","112/112 [==============================] - 222s 2s/step - loss: 1.0978 - accuracy: 0.6481 - val_loss: 1.0792 - val_accuracy: 0.5991 - lr: 0.0010\n","Epoch 31/50\n","112/112 [==============================] - 221s 2s/step - loss: 1.0871 - accuracy: 0.6524 - val_loss: 1.0462 - val_accuracy: 0.6211 - lr: 0.0010\n","Epoch 32/50\n","112/112 [==============================] - 221s 2s/step - loss: 1.0763 - accuracy: 0.6591 - val_loss: 1.0292 - val_accuracy: 0.6232 - lr: 0.0010\n","Epoch 33/50\n","112/112 [==============================] - 221s 2s/step - loss: 1.0669 - accuracy: 0.6660 - val_loss: 1.0307 - val_accuracy: 0.6291 - lr: 0.0010\n","Epoch 34/50\n","112/112 [==============================] - 221s 2s/step - loss: 1.0685 - accuracy: 0.6627 - val_loss: 1.2049 - val_accuracy: 0.5692 - lr: 0.0010\n","Epoch 35/50\n","112/112 [==============================] - 221s 2s/step - loss: 1.0231 - accuracy: 0.6864 - val_loss: 0.8985 - val_accuracy: 0.6708 - lr: 1.0000e-04\n","Epoch 36/50\n","112/112 [==============================] - 221s 2s/step - loss: 1.0002 - accuracy: 0.6979 - val_loss: 0.8875 - val_accuracy: 0.6741 - lr: 1.0000e-04\n","Epoch 37/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9966 - accuracy: 0.7004 - val_loss: 0.8948 - val_accuracy: 0.6730 - lr: 1.0000e-04\n","Epoch 38/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9884 - accuracy: 0.7046 - val_loss: 0.8924 - val_accuracy: 0.6736 - lr: 1.0000e-04\n","Epoch 39/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9807 - accuracy: 0.7063 - val_loss: 0.8911 - val_accuracy: 0.6780 - lr: 1.0000e-04\n","Epoch 40/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9755 - accuracy: 0.7061 - val_loss: 0.8863 - val_accuracy: 0.6761 - lr: 1.0000e-04\n","Epoch 41/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9723 - accuracy: 0.7128 - val_loss: 0.8866 - val_accuracy: 0.6739 - lr: 1.0000e-04\n","Epoch 42/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9621 - accuracy: 0.7156 - val_loss: 0.8845 - val_accuracy: 0.6807 - lr: 1.0000e-04\n","Epoch 43/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9634 - accuracy: 0.7177 - val_loss: 0.8903 - val_accuracy: 0.6818 - lr: 1.0000e-04\n","Epoch 44/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9609 - accuracy: 0.7139 - val_loss: 0.8848 - val_accuracy: 0.6825 - lr: 1.0000e-04\n","Epoch 45/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9604 - accuracy: 0.7145 - val_loss: 0.8833 - val_accuracy: 0.6840 - lr: 1.0000e-04\n","Epoch 46/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9590 - accuracy: 0.7173 - val_loss: 0.8881 - val_accuracy: 0.6789 - lr: 1.0000e-04\n","Epoch 47/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9509 - accuracy: 0.7191 - val_loss: 0.8826 - val_accuracy: 0.6836 - lr: 1.0000e-04\n","Epoch 48/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9518 - accuracy: 0.7209 - val_loss: 0.8915 - val_accuracy: 0.6750 - lr: 1.0000e-04\n","Epoch 49/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9388 - accuracy: 0.7272 - val_loss: 0.8831 - val_accuracy: 0.6828 - lr: 1.0000e-04\n","Epoch 50/50\n","112/112 [==============================] - 221s 2s/step - loss: 0.9375 - accuracy: 0.7294 - val_loss: 0.8937 - val_accuracy: 0.6779 - lr: 1.0000e-04\n","29/29 [==============================] - 16s 530ms/step - loss: 0.8849 - accuracy: 0.6853\n","Test loss: 0.8849025368690491\n","Test accuracy: 0.6852883696556091\n"]}]}]}